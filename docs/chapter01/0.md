---
layout: page-sidenav
group: "Chapter. 1"
title: "1.0 Introduction"
---

<!--
![figure1.1]({{ site.baseurl }}/images/Figure1.1.png){:class="center-block" height="120px"}
-->

## 소개

현재 필자가 속해있는 인공지능 스터디에서 딥러닝북을 한 주에 한 챕터씩(?) 공부하고 있다. 이 지식이 언젠간 기억의 저편으로 날아가버릴 것을 생각하니 가슴이 아파서 블로그에 글 쓰듯 시간 되는대로 정리를 하려고 한다. 중요한 내용을 중점적으로 정리할 예정이며, 너무 세세한 내용은 다루지 않고 넘어갈 수도 있다. 또한 필자의 주관적인 해석도 들어갈 수 있음을 미리 명시한다.  

## Introduction


### 딥러닝 북
[딥러닝 북](www.deeplearingbook.org)은 요슈아 벤지오 교수님과 굳 펠로우, 긜고 몬트리올 대학교의 애론 코빌 팀이 함께 작업하여 만든 딥러닝계의 바이블 중 하나이다. HTML 형식으로 온라인에서 볼 수 있으며, 원한다면 아마존 등에서 종이책으로 구입할 수 있다.


### 딥러닝 북의 구성
딥러닝 북의 구성은 크게 세 파트로 나뉘어져있다.
- **Part 1: Applied Math and Machine Learning Basics**   
  딥러닝을 이해하기 위한 기본적인 수학 개념, 그리고 머신러닝 개념을 소개한다.
- **Part 2: Modern Practical Deep Networks**   
  이미 잘 적립된 딥러닝 알고리즘들을 다룬다.
- **Part 3: Deep Learning Research**   
  미래의 딥러닝 연구에서 중요한 역할을 하게 될 것이라고 여겨지는 아이디어들, 연구들을 소개한다.

### 용어 설명 및 딥러닝의 개념
본 파트에서는 용어 설명과 더불어 이 책에서 설명하고자 하는 것들을 대략적으로 설명해준다. 하나하나 알아보도록 하자.

1. **Artificial Intelligence**   
발명가들은 오랜 세월동안 생각하는 기계를 만들기를 꿈꿔왔다. 인공지능은 생각하는 기계를 뜻한다. 너무 추상적이니, 좀 더 자세히 이야기해보자.    
컴퓨터가 세상에 나오고 얼마 되지 않았던 인공지능 초창기에는, 사람에게 어렵지만 상대적으로 컴퓨터가 풀기에는 쉬운 문제들을 컴퓨터로 풀며 이것이 인공지능이라고 생각했다. 사람에게 PI 의 소수 812315124234번째 자리를 구하라고 하면 평생 풀어도 못풀겠지만 컴퓨터는 매우 빨리 잘 풀더라는 것.    
하지만 곧 이것은 인류가 오래전부터 생각해오던 인공지능이 아니라고 발명가들은 느꼈다. 그들은 인공지능이 한계를 돌파해야만 한다고 생각했다. 인공지능이 행하기 어려운 것이 무엇인가. 무엇을 할 줄 알아야 인공지능이라고 할 수 있겠는가. 바로 사람이 쉽게 하지만 그것을 정갈하게 묘사하는 것이 어려운 일들이다. 직관, 느낌, 언어를 알아듣고 얼굴을 인식하는것 등 말이다. 그리고 이런 일들을 할 수 있어야 인공지능이라고 불릴 수 있다고 발명가들은 생각했다.    
이 책에서는 인공지능을 인공지능답게 해주는 솔루션이 딥러닝이라고 하니, 딥러닝에 대해 한번 들여다볼만 하지 않을까.

1. **Deep Learning**   
위에서 언급했듯, 결국 인공지능에게 사람이 할 수 있는 것들을 할 수 있는 것이 딥러닝이라는데, 역시 좀 더 자세히 알아보자.    
딥러닝북에서는 인공지능이 이런 일을 하는 것이 가능해지려면, 컴퓨터가 이 세상을 개념의 계층 구조로써 경험으로부터 배울 수 있어야 한다고 한다.    
경험으로부터 배워야 한다는 것은 곧 사람이 모든 특정 지식을 컴퓨터에 형식적으로 알려줄 필요 없이, 알아서 배울 수 있어야 한다는 것이고, 개념의 계층은 컴퓨터가 복잡한 개념을 쉬운 개념을 바탕으로 이해할 수 있도록 해 준다. 만약 우리가 이 개념들을 그래프로 그려본다면, 이는 무수히 많은 층들을 가진 깊은 그래프일 것이다. 발명가들은 인공지능을 만들기 위한 이러한 접근을 딥 러닝이라고 부른다.
1. **Knowledge base approach**   
따라서 발명가들은 컴퓨터가 세상을 이해할 수 있도록, 존재하는 모든 개념들의 계층구조를 어떠한 형태로든지 컴퓨터에게 전달할 수 있어야 했다. 하지만, 인간이 이해하고 있는 개념들은 너무나 추상적이고 주관적이며, 무언가로 표현하는 것 자체가 힘들었다.   
몇몇 인공지능 프로젝트들은 지식을 정해진 언어로 하드코딩하는 방법을 연구했다. 컴퓨터는 하드코딩된 지식에 논리적인 룰을 통해 추론할 수 있었다. AI에 대한 이런 접근을 Knowledge base approach라고 한다. 이런 접근방식을 가진 프로젝트들 중에 성공한 프로젝트는 거의 없다. Knowledge base project 중에 가장 유명했던 것이 Cyc(Lenat and Guha, 1989) 이다.   
Cyc는 데이터베이스에 CycL 이라는 언어로 쓰여있는 문장(지식)들을 갖고있는 지식 추론 엔진이다. 발명가들은 세상을 정확히 묘사할 정도로 충분한 복잡도를 갖고있는 룰을 고안하는데에 온힘을 쏟았다. 하지만 Cyc 는 사람만큼 추론을 해내지 못했고 실패했다. (Cyc 는 다음과 같은 오류를 범했다고 한다. 아침에 면도하는 철수의 이야기를 들려주었다니, 사람은 전기부품으로 이루어져있지 않은데 면도하는 철수는 전기 면도기를 들고있으니 '면도하는 철수는 인간인가요?' 라고 물었다고 한다.)    
여하튼 이러한 Knowledge base approach 의 실패는 **AI시스템이 데이터로부터 어떤 패턴을 추출하여, 그들만의 지식을 획득하는 능력**을 지녀야한다는 것을 알게 해주었다.

1. **Machine Learning**   
이것이 바로 머신러닝이다! 기계에게 데이터로부터 어떤 패턴을 추출하여 지식을 획득하는 능력을 갖게 하는것이다. 컴퓨터가 실제 세계의 지식을 포함하는 문제들을 풀어내고, 주관적인 것 처럼 보이는 결정들을 하는 것이다.   
 간단한 머신러닝의 예로는, Logistic regression 을 통해 산모에게 제왕절개를 추천해줄지 말지를 결정한다던가, Naive Bayes 을 통해 이메일에서 스팸메일을 분류해낸다던가 하는 것들이 있다. 모두 실제하는 세상의 기존 데이터를 바탕으로 새로운 데이터에 대한 판단을 내리도록 기계를 학습시키는 예제들이다.

1. **Representation**   
이런 간단한 머신러닝 알고리즘들의 성능은 그들에게 부여된 데이터의 표현(Representation)에 매우매우 좌지우지된다.    
제왕절개를 추천해주는 AI 시스템은 환자를 직접적으로 검사하지 않는다. 대신, 의사가 시스템에게 자궁의 상처 여부, 병적 사항여부 등의 적절한 정보들을 제공해준다. 이렇게 환자를 표현(representation)한 정보를 활용하여 AI 시스템은 제왕절개를 해야할지 말아야할지 결정내리는 것이다.

1. **Feature**   
위에서, 환자를 표현하는데 쓰인 정보 하나하나를 Feature(특징) 이라고 부른다. 머신러닝 알고리즘의 성능은 데이터의 표현이 얼마나 시스템이 판단을 내리는 데에 필요한 특징들로 이루어져 있는지에 달렸다.    
이를테면, Logistic Regression 을 활용한 AI 시스템에게 환자의 MRI사진을 주고 제왕절개 추천정도를 학습시킨다면, 성능이 매우 나쁠 것이라는 것을 학습을 시켜보지 않아도 알 수 있다. 왜냐하면, MRI 사진의 각 픽셀값들은 제왕절개 추천 정도와 연관성이 거의 없을 것이기 때문이다.    

1. **Representation Learning**   
대부분의 문제에서는 어떤 특징이 추출되어야하는지 조차 알기 어렵다. 즉, 어떤 특징을 추출한 표현이 머신러닝 알고리즘을 학습시켰을 때 좋은 성능이 나올지를 아는 것 자체가 힘들다. 이런 문제점을 해결하기 위해 다른 접근을 소개한다. 바로 Representation Learning, 표현 학습이다. 이 접근법은 AI 시스템이 표현으로부터 출력 까지의 매핑 뿐만 아니라, 표현 자체도 학습하게 하는 것이다. 이 접근법을 통해 사람이 손으로 디자인한 표현을 사용하는 것 보다 훨씬 더 좋은 성능을 낼 수 있다. 또한, AI 시스템이 새로운 문제에 사람의 중개 없이 빠르게 적응할 수 있도록 도와준다. 그리고 좋은 특징 집합을 발견할 수 있는데, 이를 연구자들이 했다면 정말 오래 걸리는 일이었을 테니 결과적으로 사람의 시간도 절약해주는 좋은 접근법이라고 할 수 있겠다.

1. **Autoencoder**   
표현 학습의 가장 본질적인 예가 바로 오토인코더이다. 오토인코더는 인코더 함수와 디코더 함수의 결합으로 이루어져 있다. 인코더 함수는 인풋 데이터를 서로 다른 표현으로 변환해주도록, 디코더 함수는 새로운 표현을 다시 원래의 포멧으로 복구하도록 학습된다. 오토인코더는 학습을 통해 데이터의 다양한 속성들을 표현할 수 있게 된다.
1. **Factors of variation**   
그렇다면 표현 학습에서 배우는 표현, 즉 특징의 집합의 실체는 무엇일까. 바로 관측한 데이터를 다양하게 만드는 요소들이다. 이를 Factors of variation 이라고 한다. 이들은 데이터로부터 직접적으로 측정할 수 있을 수도 있고 없을 수도 았다. 이를테면, 음성 데이터로부터 화자를 분류하는 문제를 풀 때, 우리가 배워야 하는 특징은 각 목소리별로 성별, 나이, 음의 높낮이, 성대의 길이 등이 될 것이다. 자동차 사진을 분석해야한다면 하면 자동차의 색, 포지션, 빛의 각도 등이 바로 Factors of variation이 된다. 위에서 언급했듯이 데이터의 다양성을 잘 표현하는 요소들을 Raw data 로부터 추출해내는 작업은 매우 어렵다. 그리고 딥러닝은 간단한 개념을 조합하여 상위 개념을 표현하는 방식으로 표현 학습을 진행하기 때문에, 사람에 비해 특징 추출을 잘 해낸다. 그림 1.2 에서 딥러닝의 표현 학습을 확인할 수 있다.

![figure1.2]({{ site.baseurl }}/images/figure1.2.png){:class="center-block" height="400px"}
[figure 1.2]

## 요약
요약하자면 딥러닝은 인공지능에 다다르는 접근 중 하나이다. 컴퓨터 시스템이 데이터와 경험을 통해 개선되도록 하는 기술이다. 이 책의 저자들에 따르면, 머신 러닝은 복잡한 이 세상 환경에서 작동하는 AI 시스템을 만들 수 있는 가능성 있는 유일한 방법이다. 딥러닝은 이 세상의 개념들을 계층 구조로 배울 수 있는 표현 학습 능력을 지닌 머신 러닝 중 하나이다. 그림 1.4 와 1.5는 딥러닝의 개념적 위치를 그려놓았다. 위의 내용과 일치하는지 한번 살펴보도록 하자.

![figure1.4]({{ site.baseurl }}/images/figure1.4.png){:class="center-block" height="400px"}
[figure 1.4]

![figure1.5]({{ site.baseurl }}/images/figure1.5.png){:class="center-block" height="400px"}
[figure 1.5]
